[
    {
        "id": "126106_1",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_考試樣題_126106",
        "L1": "L11_人工智慧基礎概論",
        "L2": "L111_人工智慧概念",
        "tags": [],
        "Q": "下列何者並未使用人工智慧(AI)或機器學習(ML)技術？",
        "A": "使用一組預定義規則來確定最佳移動做法的象棋遊戲",
        "B": "使用深度神經網路來提高其準確性的語音識別系統",
        "C": "使用感測器和預定義的自動駕駛汽車-定義導航規則",
        "D": "使用自然語言處理算法來理解和反應用戶查詢的聊天機器人",
        "Ans": "A",
        "has_img": false,
        "Exp": "傳統規則式系統（If-Then）是由人寫死邏輯，並未具備自主學習數據特徵的能力。",
        "Ex": "就像按照食譜一步步做菜的機器人，如果沒寫在食譜上的狀況，它就不會處理。",
        "Va": "分辨專家系統與機器學習的差異；沒了區分，我們無法選擇最合適的技術路徑。",
        "Dif": "B、D 是標準 AI 應用；C 選項雖包含預定義規則但現代自駕多包含 ML 混合。"
    },
    {
        "id": "126106_2",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_考試樣題_126106",
        "L1": "L23_機器學習技術與應用",
        "L2": "L232_機器學習與深度學習",
        "tags": [],
        "Q": "在文本資料處理過程中，通常會需要「將接續的文本轉換為詞彙單位」，以便後續的處理。請問上述所指的是文本資料處理中的哪一個方法？",
        "A": "詞形還原(Lemmatization)",
        "B": "停用詞移除(StopwordRemoval)",
        "C": "斷詞(Tokenization)",
        "D": "詞頻-逆向文件頻率(TermFrequency-InverseDocumentFrequency,TF-IDF)",
        "Ans": "C",
        "has_img": false,
        "Exp": "將長句子切分成最小意義單位（Tokens），是 NLP 預處理的第一步。",
        "Ex": "就像把一長串珍珠項鍊剪斷，變成一顆顆獨立的珍珠，方便後續分類或計數。",
        "Va": "搜尋引擎分詞索引；沒了斷詞，電腦只能將整段文字當成單一雜亂訊號，無法分析。",
        "Dif": "A 是統一時態根源；B 是刪除虛詞；D 是計算詞彙重要性的權重方法。"
    },
    {
        "id": "126106_3",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_考試樣題_126106",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "下列何者為自然語言處理(NLP)在機器學習應用中的主要用途？",
        "A": "情緒分析",
        "B": "圖像識別",
        "C": "預測性維護",
        "D": "供應鏈優化",
        "Ans": "A",
        "has_img": false,
        "Exp": "NLP 專注於讓機器理解人類語言，分析文字背後的正負向情感是其經典應用。",
        "Ex": "像是百貨公司的自動評論監測器，能自動抓出哪則留言是在罵客服、哪則是誇獎。",
        "Va": "公關危機預警、社群輿論監控；沒了它，企業無法在大數據時代即時掌握民意。",
        "Dif": "B 是電腦視覺範疇；C、D 多屬於迴歸或運籌優化問題。"
    },
    {
        "id": "126106_4",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_考試樣題_126106",
        "L1": "L23_機器學習技術與應用",
        "L2": "L232_機器學習與深度學習",
        "tags": [],
        "Q": "關於深度學習模型，下列敘述何者不正確？",
        "A": "卷積神經網路(ConvolutionalNeuralNetworks)適合影像辨識",
        "B": "ReLU(RectifiedLinearUnit)比tanh和Sigmoid好，因為ReLU可以減緩梯度爆炸與消失",
        "C": "遞迴神經網路(RecurrentNeuralNetworks)適合處理序列相關資料",
        "D": "Elman神經網路(ElmanNeuralNetworks)適合處理影像辨識",
        "Ans": "D",
        "has_img": false,
        "Exp": "Elman 神經網路是一種早期的 RNN 結構，主要用於序列資料，而非影像處理。",
        "Ex": "就像拿著錄音筆去拍合照（Elman），雖然都是工具，但完全用錯了地方。",
        "Va": "釐清模型強項能避免研發時選錯工具；沒了正確分類，訓練效果將事倍功半。",
        "Dif": "A、C 為基本共識；B 是現代深度學習活化函數的首選原則。"
    },
    {
        "id": "126106_5",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_考試樣題_126106",
        "L1": "L11_人工智慧基礎概論",
        "L2": "L111_人工智慧概念",
        "tags": [],
        "Q": "下列何者為機器學習模型在業界部署的主要趨勢？",
        "A": "越來越多地採用自動化機器學習(AutoML)技術",
        "B": "轉向使用更簡單的機器學習算法",
        "C": "基於雲的機器學習平台的使用率下降",
        "D": "依賴手動超參數調整進行模型優化",
        "Ans": "A",
        "has_img": false,
        "Exp": "AutoML 讓非專業開發者也能自動尋找最佳模型與參數，降低 AI 落地門檻。",
        "Ex": "就像從手排車（手動調參）進化到自排車（AutoML），讓更多人能輕鬆上路。",
        "Va": "協助企業快速測試 AI 方案可行性；沒了它，AI 轉型將高度依賴昂貴的人才技術。",
        "Dif": "B、C、D 與現行業界朝向複雜化、雲端化、自動化的發展趨勢相反。"
    },
    {
        "id": "126106_6",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_考試樣題_126106",
        "L1": "L22_大數據處理分析與應用",
        "L2": "L221_機率統計基礎",
        "tags": [],
        "Q": "在巨量資料分析班中，共有一年級至四年級，每個年級有50個學生，且學生身高呈常態分佈。下列敘述何者不正確？",
        "A": "要檢測一年級和二年級的平均身高是否有差異，可以利用t檢定",
        "B": "要檢測一年級、二年級、三年級之間的平均身高是否有差異，可以利用t檢定",
        "C": "要檢測二年級、三年級、四年級之間的平均身高是否有差異，可以利用F檢定",
        "D": "要檢測一年級的平均身高是否等於170公分，可以利用卡方檢定",
        "Ans": "D",
        "has_img": false,
        "Exp": "卡方檢定用於類別資料的比例檢定，身高等連續變數的均值比對應用 T 或 Z 檢定。",
        "Ex": "就像量身高（連續）卻用計人數（類別）的計算機，工具與資料性質完全不符。",
        "Va": "確保數據分析結論的統計嚴謹性；選錯統計方法會導致科學性的錯誤論證。",
        "Dif": "A、B、C 描述了 T 檢定（兩組）與 ANOVA/F 檢定（三組以上）的正確認知。"
    },
    {
        "id": "126106_8",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_考試樣題_126106",
        "L1": "L23_機器學習技術與應用",
        "L2": "L233_機器學習建模與參數調校",
        "tags": [],
        "Q": "下列何者不屬於特徵工程(FeatureEngineering)？",
        "A": "轉換(Transformation)",
        "B": "萃取(Extraction)",
        "C": "挑選(Selection)",
        "D": "預測(Prediction)",
        "Ans": "D",
        "has_img": false,
        "Exp": "特徵工程是在幫資料「打底」，而預測是模型訓練完成後的「最終產出行為」。",
        "Ex": "特徵工程是洗菜、切菜、調味；預測則是菜煮好端上桌給客人品嚐。",
        "Va": "明確區分資料準備與推理階段；沒了清晰的步驟畫分，模型開發流程會混亂。",
        "Dif": "A、B、C 均為提升資料特徵對模型解釋力、降低雜訊的關鍵前置處理。"
    },
    {
        "id": "126106_13",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_考試樣題_126106",
        "L1": "L11_人工智慧基礎概論",
        "L2": "L111_人工智慧概念",
        "tags": [],
        "Q": "當模型的訓練誤差(TrainingError)低、但測試誤差(TestError)很大時，這通常是在訓練過程中產生下列哪一種情況？",
        "A": "模型的泛化能力強",
        "B": "模型出現過度擬合(Overfitting)",
        "C": "模型出現欠擬合(Underfitting)",
        "D": "訓練資料和測試資料之間沒有相關性",
        "Ans": "B",
        "has_img": false,
        "Exp": "模型死背了訓練集的細節與雜訊，導致遇到沒看過的資料時表現極差。",
        "Ex": "學生死背考古題答案，考試時換個數字就不會寫，這就是過度擬合。",
        "Va": "開發模型時需監控驗證曲線；沒了這觀念，模型上線後預測準確度會崩盤。",
        "Dif": "A 是測試誤差也低的情況；C 是兩者誤差都高；D 屬資料分布不一致的問題。"
    },
    {
        "id": "136295_11",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_科目2_大數據處理分析與應用_136295",
        "L1": "L22_大數據處理分析與應用",
        "L2": "L224_大數據在人工智慧之應用",
        "tags": [],
        "Q": "在 AI 倫理治理的背景下，「透明性(Transparency)」通常是指什麼？",
        "A": "AI 系統的運算速度公開",
        "B": "AI 系統僅使用公開數據",
        "C": "AI 系統決策流程清晰且可解釋",
        "D": "所有 AI 模型都是開源的",
        "Ans": "C",
        "has_img": false,
        "Exp": "指系統如何得出結論的邏輯應被人類理解與審核，避免黑箱決策造成不公。",
        "Ex": "像法官判刑必須給出理由，不能只說「我感覺他有罪」而不解釋邏輯。",
        "Va": "在醫療或貸款審核 AI 中，沒了透明性，被拒絕的人將無從申訴或理解原因。",
        "Dif": "A、B、D 屬於效能、數據來源或授權協議，非倫理中核心的決策解釋權。"
    },
    {
        "id": "136295_14",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_科目2_大數據處理分析與應用_136295",
        "L1": "L22_大數據處理分析與應用",
        "L2": "L224_大數據在人工智慧之應用",
        "tags": [],
        "Q": "為了加速大數據環境下的 AI 模型訓練，以下哪一項為常見技術？",
        "A": "早期停止(Early Stopping)",
        "B": "批次分群(Mini-batching)",
        "C": "混合精度訓練(Mixed Precision Training)",
        "D": "主成分分析(PCA)",
        "Ans": "C",
        "has_img": false,
        "Exp": "混合精度利用 FP16 降低記憶體消耗並加速運算，同時維持必要的準確度。",
        "Ex": "像做簡單加法用計算機，遇到微小數值才動腦精算，效率大幅提升。",
        "Va": "訓練大型語言模型時，沒了此技術，訓練時間與成本將高到無法負荷。",
        "Dif": "A 是防止過擬合；B 是常規訓練法；D 是降維，不直接指代計算精度的優化。"
    },
    {
        "id": "136295_15",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_科目2_大數據處理分析與應用_136295",
        "L1": "L22_大數據處理分析與應用",
        "L2": "L224_大數據在人工智慧之應用",
        "tags": [],
        "Q": "考慮使用 CIFAR-10 資料集進行資料處理，資料包括 32×32 像素的多筆彩色照片。下列程式碼的資料處理，請選出正確的選項。",
        "A": "訓練集(x_train)資料集個數為 100000 筆",
        "B": "測試集(x_test)資料集個數為 10000 筆",
        "C": "訓練集(x_train)是 Pandas 資料框(DataFrame)物件",
        "D": "如果希望將訓練集(x_train)像素值轉換為[0, 1]的範圍，則可以輸入：x_train = x_train.astype('int32') / 255.0",
        "Ans": "B",
        "has_img": false,
        "Exp": "CIFAR-10 標準定義為 5 萬張訓練圖、1 萬張測試圖，且格式為 NumPy 陣列。",
        "Ex": "像買一箱 100 顆的蘋果，規格就是固定的，CIFAR-10 的測試組就是固定 1 萬顆。",
        "Va": "了解標準資料集規模，能幫助在載入模型時預估記憶體需求與驗證流程。",
        "Dif": "A 筆數過多；C 應為 NumPy Array；D 應轉換為 float 浮點數才能除出小數。"
    },
    {
        "id": "136300_6",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_科目3_機器學習技術與應用_136300",
        "L1": "L23_機器學習技術與應用",
        "L2": "L231_機器學習基礎數學",
        "tags": [],
        "Q": "在分類任務中，深度學習模型通常搭配哪一種輸出函數？",
        "A": "Tanh",
        "B": "ReLU",
        "C": "Sigmoid 或 Softmax",
        "D": "Dropout",
        "Ans": "C",
        "has_img": false,
        "Exp": "這兩者能將輸出值壓縮到 0 與 1 之間，將數值轉化為分類機率。",
        "Ex": "像是在投票，最後把票數換算成百分比，讓你一眼看出當選某個分類的機率。",
        "Va": "辨識貓狗時，沒了 Softmax 就無法得出機率結論，只有一堆無序數字。",
        "Dif": "A、B 多用於隱藏層激發函數；D 是防止過擬合的技術，非輸出函數。"
    },
    {
        "id": "136300_8",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_科目3_機器學習技術與應用_136300",
        "L1": "L23_機器學習技術與應用",
        "L2": "L231_機器學習基礎數學",
        "tags": [],
        "Q": "在神經網路中，前向傳播(Forward Propagation)主要依賴下列哪一種數學操作？",
        "A": "機率積分",
        "B": "矩陣乘法與向量內積",
        "C": "對數變換",
        "D": "條件機率推論",
        "Ans": "B",
        "has_img": false,
        "Exp": "網路每一層計算本質上是輸入向量與權重矩陣相乘，再加上偏差值的運算。",
        "Ex": "像製作多層調酒，每一層都是不同的配方比例混合後往下一層傳遞。",
        "Va": "這是神經網路運算最頻繁的部分，也是為何模型需要 GPU 進行平行加速的主因。",
        "Dif": "A、C、D 雖在其他統計或損失計算中出現，但非傳播過程的底層基礎運算。"
    },
    {
        "id": "136300_13",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_科目3_機器學習技術與應用_136300",
        "L1": "L23_機器學習技術與應用",
        "L2": "L233_機器學習建模與參數調校",
        "tags": [],
        "Q": "在進行模型訓練前，若針對資料中不同群體(例如分類標籤)之間樣本數量不平衡的情況進行比例調整，此方法通常屬於下列哪一種技術？",
        "A": "資料重抽樣",
        "B": "特徵選擇",
        "C": "模型正則化",
        "D": "超參數調整",
        "Ans": "A",
        "has_img": false,
        "Exp": "透過複製少數類或刪減多數類來平衡類別，讓模型學習不產生偏見。",
        "Ex": "像班上有 9 份數學卷 1 份國文卷，影印多份國文卷讓比例變 1:1。",
        "Va": "在偵測罕見疾病時，沒了重抽樣，模型會因為樣本太少而直接忽視患者。",
        "Dif": "B 選取欄位；C 防止過擬合；D 是調整架構設定，皆不處理資料比例。"
    },
    {
        "id": "136300_15",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年iPAS AI_中級_科目3_機器學習技術與應用_136300",
        "L1": "L23_機器學習技術與應用",
        "L2": "L233_機器學習建模與參數調校",
        "tags": [],
        "Q": "15某零售公司希望利用顧客的年齡與每月消費金額，預測顧客是否為高價值顧客。\n提供相關資料 data.csv，包含欄位 Age、Spending、 HighValue。\n請將下列程式碼片段依正確順序排序，以完成模型的建立與預測。",
        "A": "c → a → b → d",
        "B": "a → c → b → d",
        "C": "c → b → a → d",
        "D": "b → a → c → d",
        "Ans": "A",
        "has_img": false,
        "Exp": "開發邏輯為：讀取資料(c) → 宣告模型(a) → 餵資料訓練(b) → 最後進行預測(d)。",
        "Ex": "像做菜：先買菜（讀檔），準備好鍋子（宣告模型），開火炒菜（訓練），最後裝盤上桌（預測）。",
        "Va": "沒了正確順序，模型會因找不到資料或尚未訓練而報錯，導致系統無法運行。",
        "Dif": "B、D 先宣告或訓練但沒讀資料；C 順序錯亂，尚未宣告模型無法進行訓練。"
    },
    {
        "id": "136301_1",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某電商企業希望利用自然語言處理(NLP)技術，分析顧客在社群平台與商品評論中的文字內容，以即時掌握顧客對產品的滿意度變化。若採用情感分析(Sentiment Analysis)模型，其主要目的為何？",
        "A": "預測顧客使用的語言風格與語氣",
        "B": "判斷文本中所表達的情感傾向",
        "C": "將顧客留言自動翻譯成企業內部指定語言",
        "D": "產生顧客評論的自動化摘要內容",
        "Ans": "B",
        "has_img": false,
        "Exp": "情感分析核心在於辨識文字背後的情緒，如正向（讚美）或負向（投訴）。",
        "Ex": "像讀心術，把「這什麼爛東西」標記為生氣，把「超好用」標記為開心。",
        "Va": "用於公關危機監控，沒了它，企業需耗費巨大人力逐一閱讀留言才能發現負評。",
        "Dif": "A 是語言風格辨識；C 是機器翻譯；D 是文本摘要，均非情感偵測。"
    },
    {
        "id": "136301_2",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某跨國金融科技公司導入 Transformer 架構開發多語客服系統，以提升長篇金融文件的自動翻譯品質。下列何者為該模型能顯著改善翻譯準確度的主要原因？",
        "A": "透過自注意力機制(Self-Attention Mechanism)捕捉長距離語境依賴關係",
        "B": "透過卷積運算(Convolution Operation)加速訓練過程",
        "C": "透過強化學習(Reinforcement Learning)自動調整語句生成策略",
        "D": "透過資料增強(Data Augmentation)平衡多語語料比例",
        "Ans": "A",
        "has_img": false,
        "Exp": "Self-Attention 讓模型在處理某個詞時，能同時觀察整句話的其他關鍵詞，無論距離多遠。",
        "Ex": "像看推理小說，能隨時回想起第一章的伏筆來理解結局，不會讀到後面忘記前面。",
        "Va": "沒了它，模型處理長難句時會「顧此失彼」，導致代名詞指代錯誤或邏輯斷裂。",
        "Dif": "B 是 CNN 的特色；C、D 是訓練技巧，非 Transformer 結構提升準確度的核心機制。"
    },
    {
        "id": "136301_3",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某企業計畫應用 BERT(Bidirectional Encoder Representations from Transformers)模型分析大量顧客意見，以強化客服自動回覆系統。\n在 BERT 的預訓練過程中，「遮罩語言模型(Masked Language Model, MLM)」的主要訓練策略為何？",
        "A": "依序遮罩句尾詞語，讓模型從左到右逐步生成完整句子",
        "B": "隨機遮罩部分詞語，並讓模型根據雙向上下文(Bidirectional Context)預測被遮罩的詞",
        "C": "透過對抗訓練(Adversarial Training)生成語意相似的擾動樣本以提升泛化性",
        "D": "以未遮罩的詞為條件，使用解碼器(Decoder)結構重建整句內容",
        "Ans": "B",
        "has_img": false,
        "Exp": "MLM 像填空題，挖掉中間詞彙後讓模型觀察前後文來猜出正確答案。",
        "Ex": "像玩「填字遊戲」，你得看前後文字才能猜出格子裡該填什麼，從而理解語意。",
        "Va": "沒了這種雙向訓練，模型將難以理解同一個詞在不同語境下的多重含義。",
        "Dif": "A 是 GPT 的單向策略；C 是強健性訓練；D 是編碼解碼器架構的常見做法。"
    },
    {
        "id": "136301_4",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "在詞向量(Word Embedding)訓練方法中，GloVe(Global Vectors for Word Representation)與 Word2Vec 的主要差異為何？",
        "A": "Word2Vec 以詞頻權重訓練詞向量，而 GloVe 以隨機初始化向量進行學習",
        "B": "Word2Vec 以全局統計矩陣為基礎，而 GloVe 採用神經網路進行上下文預測",
        "C": "Word2Vec 為基於預測的模型，而 GloVe 為基於共現統計的模型",
        "D": "Word2Vec 僅能用於靜態文本語料，而 GloVe 可應用於即時語料更",
        "Ans": "C",
        "has_img": false,
        "Exp": "Word2Vec 透過滑動視窗預測相鄰詞；GloVe 則統計整個語料庫中詞彙同時出現的頻率。",
        "Ex": "Word2Vec 像跟蹤狂觀察你旁邊是誰；GloVe 則像戶政事務所統計全台人口分布。",
        "Va": "沒了 GloVe 這種全局統計，模型可能較難捕捉到跨文件、宏觀的語意關聯。",
        "Dif": "A、B 描述完全相反；D 兩者皆主要用於離線靜態語料訓練。"
    },
    {
        "id": "136301_5",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某企業以詞頻–逆文件頻率(Term Frequency–Inverse Document Frequency, TF-IDF)方法分析顧客意見內容，但發現模型在處理篇幅較長的回饋文本時，無法準確反映關鍵詞的重要性。\n下列何者為造成此現象的主要原因？",
        "A": "長文本中的詞頻偏高，導致常見詞權重被過度放大",
        "B": "長文本中缺乏明確句子邊界，造成 TF-IDF 無法計算詞頻",
        "C": "TF-IDF 無法同時處理多份文件",
        "D": "長文本會改變 IDF(Inverse Document Frequency)的計算，使所有詞權重趨於相近",
        "Ans": "A",
        "has_img": false,
        "Exp": "TF 僅看出現次數，長文裡廢話出現次數也多，容易蓋過真正有意義但次數略少的關鍵字。",
        "Ex": "像算總分，話多的人（長文）就算講廢話也能累積高分，讓重點被雜訊淹沒。",
        "Va": "處理法律或長篇合約時，若不改用 BM25 或詞嵌入，TF-IDF 常會抓錯重點。",
        "Dif": "B、C 與原理不符；D IDF 是由文件總數決定，與單篇長短無直接統計關聯。"
    },
    {
        "id": "136301_6",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某企業嘗試以 N-gram 語言模型(N-gram Language Model)建立客服自動回覆系統，但發現模型生成的句子雖在片段上合理，卻缺乏整體語意連貫性。\n此問題最可能源自 N-gram 模型的哪一項限制？",
        "A": "N-gram 模型在訓練過程中需要龐大計算量，導致長句無法收斂",
        "B": "N-gram 模型僅根據固定長度的前序詞建立機率估計，難以捕捉長距離依賴關係(Long-range Dependencies)",
        "C": "N-gram 模型缺乏語意嵌入(Semantic Embedding)層，因此無法表徵詞語間的語意相似度",
        "D": "N-gram 模型假設詞與詞之間相互獨立，導致無法建構上下文語意關聯",
        "Ans": "B",
        "has_img": false,
        "Exp": "N-gram 只看前幾個字，就像記憶力只有三秒的魚，講到後面就忘了前面說過什麼。",
        "Ex": "像接龍，你只看前一個字決定下一個，卻沒思考整句話的主題是什麼。",
        "Va": "在生成長篇文章時，沒了 Transformer 這種能看全域的技術，產出的文章會前言不對後語。",
        "Dif": "A 計算量其實比深度學習小；C 雖是事實但非「不連貫」的主因；D 描述的是單純的貝氏假設。"
    },
    {
        "id": "136301_7",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "在企業導入的智慧監控系統中，模型以物件偵測(Object Detection)方式自動辨識影像中的人物與車輛。\n若評估指標採用平均精確率(Mean Average Precision, mAP)，其中 IoU (Intersection over Union)閾值設定較高時，代表下列哪一項意義？",
        "A": "預測邊界框與真實邊界框的重疊程度越高，模型偵測結果越精準",
        "B": "預測邊界框與真實邊界框的誤差越大，導致 mAP 數值上升",
        "C": "模型整體精確率(Precision)降低，但召回率(Recall)上升",
        "D": "預測邊界框的評估結果不受真實框大小影響",
        "Ans": "A",
        "has_img": false,
        "Exp": "IoU 越高代表預測框跟實際框對得越準，門檻設高就是要求「框得非常貼合」才算對。",
        "Ex": "像投籃，籃框（閾值）越小，球得投得越準才算進分，誤差容忍度變極低。",
        "Va": "在自駕車辨識行人時，沒了高 IoU 要求，框框偏移可能導致煞車時距離誤判。",
        "Dif": "B 誤差大會導致數值下降；C 通常兩者皆降；D IoU 計算本質與大小比例有關。"
    },
    {
        "id": "136301_8",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "關於 Softmax 與 Max-Pooling，下列敘述何者正確？",
        "A": "Softmax 與 Max-Pooling 都會將特徵張量壓縮為單一最大值",
        "B": "Max-Pooling 會對輸入進行機率分佈的轉換",
        "C": "Softmax 會保留所有輸入資訊，但以比例表示；Max-Pooling 只保留區域最大值",
        "D": "Softmax 主要用於特徵降維，而 Max-Pooling 用於分類輸出",
        "Ans": "C",
        "has_img": false,
        "Exp": "Softmax 是把數字變機率（總和 1）；Max-Pooling 是從一區選一個最強的代表。",
        "Ex": "Softmax 像分糖果，大家都有份（比例）；Pooling 像選班長，這區只派最強的出列。",
        "Va": "分類模型末端必須用 Softmax，沒了它就無法得出所有類別加總為 100% 的機率分佈。",
        "Dif": "A Softmax 輸出陣列而非單一值；B 它是降維；D 兩者功能描述完全寫反。"
    },
    {
        "id": "136301_9",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某企業在訓練生成式 AI 模型時，導入資料增強(Data Augmentation)技術以擴充訓練資料，但觀察到模型效能反而下降。下列哪一項最可能的原因與對應改善策略最為正確？",
        "A": "增強樣本未經隨機初始化，導致模型梯度更新不穩定，應重新設計訓練啟動流程",
        "B": "增強後資料的特徵分佈與原始資料不一致，影響模型的泛化能力，應檢查並調整增強策略以維持語意一致性",
        "C": "增強樣本的比例過高，造成模型對特定資料產生偏好，應適度提高增強比例並調整學習率",
        "D": "增強後資料的標註可信度下降，導致訓練訊號偏差，應以半監督學習方式重新校正資料",
        "Ans": "B",
        "has_img": false,
        "Exp": "若增強方式太過火（如把貓拉伸到看不出是貓），模型學到的會是錯誤規律。",
        "Ex": "像練習書法，亂寫一通雖然寫了很多（資料增加），但反而讓字寫得更醜。",
        "Va": "醫學影像增強若沒維持解剖學正確，沒了語意一致性，AI 會學會誤診偏見。",
        "Dif": "A、C 邏輯矛盾；D 雖有道理但非增強技術失敗（資料分佈偏離）的最核心原因。"
    },
    {
        "id": "136301_10",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "如果希望同時兼顧「精確率(Precision)」和「召回率(Recall)」，下列哪一個指標可以作為綜合評估的標準？",
        "A": "準確率(Accuracy)",
        "B": "均方根誤差(RMSE)",
        "C": "均方誤差(MSE)",
        "D": "F1 分數(F1 Score)",
        "Ans": "D",
        "has_img": false,
        "Exp": "F1 是兩者的調和平均數，當兩者都很高時 F1 才會高，能避免單一指標的偏誤。",
        "Ex": "像全能球員，投籃（精確）與防守（召回）都要強，平均分數才高，不能偏廢。",
        "Va": "在癌症篩檢中，沒了 F1 分數，可能導致精確度很高但漏掉一堆患者的危險狀況。",
        "Dif": "A 易受樣本不均影響；B、C 是迴歸指標，不適用於分類精確度的評估。"
    },
    {
        "id": "136301_11",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "企業資料分析團隊使用 DBSCAN(Density-Based Spatial Clustering of Applications with Noise)演算法進行顧客行為分群，並希望模型能自動區分主要群集與雜訊資料。\n在此演算法中，決定聚類結果的兩個主要超參數為下列何者？",
        "A": "特徵數與學習率",
        "B": "K 值與距離閾值",
        "C": "鄰域半徑(Epsilon ε)與最小點數(MinPts)",
        "D": "交叉熵(Cross Entropy)與權重初始化",
        "Ans": "C",
        "has_img": false,
        "Exp": "DBSCAN 是看密度：半徑(Eps)內至少要有多少點(MinPts)才算一個群體。",
        "Ex": "像揪團，方圓十公尺（半徑）內至少要有五個人（點數）才算一個小圈圈。",
        "Va": "分析地圖犯罪熱點時，沒了這兩參數，系統無法自動定義哪裡算「高密度犯罪區」。",
        "Dif": "A 是深度學習超參；B 是 K-means 或階層聚類概念；D 是損失函數。"
    },
    {
        "id": "136301_12",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某金融科技公司建立房價預測模型，使用多項特徵(如建坪、房齡、樓層、總價等)進行線性迴歸分析(Linear Regression Analysis)。\n資料分析師發現多個特徵之間存在高度相關性，導致模型係數不穩定、預測誤差上升。\n為解決此問題，下列哪一種方法最適合？",
        "A": "繼續保留所有特徵，不進行任何處理",
        "B": "使用主成分分析(PCA)將相關特徵轉換為彼此獨立的主成分",
        "C": "新增更多原始變數以提升模型表現",
        "D": "改用分類模型進行預測",
        "Ans": "B",
        "has_img": false,
        "Exp": "PCA 將相關特徵壓縮並轉為「互相垂直」的成分，澈底消除共線性問題。",
        "Ex": "像兩個員工做重複的事（相關），主管把它們濃縮成一項職責（PCA），權責更明確。",
        "Va": "進行精確預測時，沒了消除共線性的步驟，迴歸係數會亂跳，導致結果不可信。",
        "Dif": "A 讓問題持續；C 反而可能加重負擔；D 房價是數值預測，不應改用分類。"
    },
    {
        "id": "136301_13",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L213_AI技術應用與系統部署",
        "tags": [],
        "Q": "下列何者為 Kubernetes 在 AI 模型部署與運行中的核心功能？",
        "A": "自動化管理模型的訓練流程與參數調校",
        "B": "管理與協調模型服務的部署、擴展與運行環境",
        "C": "提供 AI 模型的資料儲存與版本控管功能",
        "D": "負責深度學習推論的 GPU 加速運算",
        "Ans": "B",
        "has_img": false,
        "Exp": "K8s 像模型的大管家，負責容器化服務的自動調度、自動修復與負載平衡。",
        "Ex": "像餐廳經理，負責分派桌位、人多時加派服務員（擴展），確保每桌都有人服務。",
        "Va": "在大流量 AI 應用中，沒了 K8s，一旦某個服務掛掉，就必須手動重新重啟，非常低效。",
        "Dif": "A 是 AutoML 或管道工具功能；C 屬於版本庫；D 則是由硬體驅動層負責。"
    },
    {
        "id": "136301_14",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "在調整模型超參數(Hyperparameters)時，若希望避免因過度調整參數而導致過擬合，下列哪一種做法最有效提升模型的泛化能力？",
        "A": "採用交叉驗證(Cross-Validation)於多組參數組合間反覆評估，選擇在驗證資料上表現最穩定的設定",
        "B": "使用早期停止機制(Early Stopping)監控訓練誤差並在收斂前停止訓練，以防模型學習過度",
        "C": "對輸入特徵進行標準化以減少特徵值差異帶來的過擬合風險",
        "D": "提高模型複雜度並使用更多超參數搜尋範圍，以確保模型能充分學習資料特徵",
        "Ans": "A",
        "has_img": false,
        "Exp": "交叉驗證確保參數在資料集的不同部分都行得通，而非只對某塊資料有效。",
        "Ex": "像考前猜題，不只要寫考古題，還要模擬各種試題（交叉驗證），實測才不會失靈。",
        "Va": "開發商業模型時，沒了交叉驗證，模型上線後遇到新客戶很可能精準度大崩盤。",
        "Dif": "B 是訓練中技巧；C 僅利於收斂；D 反而會增加過擬合風險。"
    },
    {
        "id": "136301_15",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L213_AI技術應用與系統部署",
        "tags": [],
        "Q": "在企業導入的 MLOps(Machine Learning Operations)流程中， Model Registry 最常用於哪一個階段？",
        "A": "用於設定運算資源與執行環境以確保訓練穩定",
        "B": "用於建立可重複使用的資料與特徵版本",
        "C": "用於集中管理模型版本、訓練紀錄與部署狀態",
        "D": "用於追蹤模型上線後的表現與漂移情況",
        "Ans": "C",
        "has_img": false,
        "Exp": "Model Registry 是模型的檔案庫，方便團隊追蹤、比較並選擇哪個版本要上線。",
        "Ex": "像遊戲存檔管理員，讓你知道哪一個存檔等級最高、在哪裡存的、隨時能讀檔。",
        "Va": "在大型團隊中，沒了 Registry，大家會分不清最新版模型在哪，造成版本混亂。",
        "Dif": "A 屬於環境設定；B 是 Feature Store；D 是 Model Monitoring。"
    },
    {
        "id": "136301_16",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "下列哪一種情境中最適合使用「序列到序列(Seq2Seq)」模型？",
        "A": "預測銷售趨勢曲線，輸出未來數值序列",
        "B": "辨識文本中出現的人名、地名與組織名稱等實體資訊",
        "C": "對輸入文本中的關鍵字進行頻率統計與可視化",
        "D": "將輸入文字轉換成語意等價的另一段文字，如自動翻譯或摘要生成",
        "Ans": "D",
        "has_img": false,
        "Exp": "核心在於輸入一段序列（文字），輸出另一段變長的序列（另一種文字）。",
        "Ex": "像口譯員，聽完一段完整的話，重新組織成另一種語言說出來。",
        "Va": "開發 Google 翻譯或文章自動摘要時，沒了 Seq2Seq 結構就無法處理變長的文本轉換。",
        "Dif": "A 是時間序列迴歸；B 是命名實體識別(NER)；C 是簡單統計。"
    },
    {
        "id": "136301_17",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "在自然語言處理中，檢索增強生成(Retrieval-Augmented Generation, RAG)是一種結合語言模型與向量搜尋的技術，可有效減少模型知識過時與產生幻覺的問題。\n若要建立一套高效能的 RAG 系統，下列何者為在「檢索階段」最關鍵的挑戰？",
        "A": "確保檢索到的文件能被完整納入語言模型的上下文視窗(Context Window)中進行生成",
        "B": "選擇使用 Faiss 或 ScaNN 等近似最近鄰搜尋函式庫",
        "C": "降低嵌入模型(Embedding Model)在高維空間中的計算成本與記憶體占用",
        "D": "避免向量檢索結果僅具語意相似但與查詢意圖無實質關聯的情況",
        "Ans": "D",
        "has_img": false,
        "Exp": "檢索最怕「詞對了但意思不對」，雖然數學上接近，但對回答使用者問題沒幫助。",
        "Ex": "像你去圖書館查「蘋果食譜」，管理員給你一堆「賈伯斯傳」，字面有關但沒意義。",
        "Va": "在企業客服 RAG 中，沒了精準檢索，AI 會根據無關文件一本正經地胡說八道（幻覺）。",
        "Dif": "A 屬於生成階段；B、C 是工程實作細節，非關乎語意檢索正確性的核心挑戰。"
    },
    {
        "id": "136301_18",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "當 Transformer 模型發生「注意力分布過於平均(Attention Collapse)」的情形時，導致模型無法有效聚焦於關鍵資訊，下列哪一項策略可有效改善此問題？",
        "A": "提高 Query-Key 點積(Dot Product)的縮放常數",
        "B": "在 Softmax 前加入高斯雜訊(Gaussian Noise)",
        "C": "使用 ReLU 函數取代 Softmax",
        "D": "對注意力權重施加稀疏化約束(Sparsity Constraint)",
        "Ans": "D",
        "has_img": false,
        "Exp": "透過稀疏化強迫模型只關注少數最重要的位置，不要對每個字都分配同樣權重。",
        "Ex": "像聚光燈，把光集中在主角身上（稀疏化），而不是把整排路燈全開亮（分布平均）。",
        "Va": "模型若太「博愛」看誰都一樣，沒了稀疏約束就抓不到重點，導致語意理解能力退化。",
        "Dif": "A、B 無法解決分布均勻問題；C ReLU 不是機率分布函數，無法直接取代輸出層。"
    },
    {
        "id": "136301_19",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某研究團隊正在訓練一個針對低資源語言(如少數民族語言)的語言模型，但該語言僅有約 1 萬筆語料可用。\n在訓練過程中出現明顯的過擬合現象，若希望在不新增真實語料的前提下提升模型的泛化能力，採用下列哪一種方法最為適合？",
        "A": "將 Transformer 的隱藏層維度擴增至 1024，以提升表徵能力",
        "B": "採用反向翻譯(Back-Translation)技術，以生成額外目標語句的偽平行語料(Pseudo‑Parallel Corpus)",
        "C": "對詞嵌入矩陣(Embedding Matrix)，施加 L1 正則化以壓縮模型參數",
        "D": "將多語言 BERT(mBERT)中所有 Transformer 層全部凍結以保留預訓練知識",
        "Ans": "B",
        "has_img": false,
        "Exp": "反向翻譯利用現有翻譯再翻回來，生成多樣的同義句來增加訓練樣本量。",
        "Ex": "像背英文，把句子翻成中文再請人用中文翻回英文，增加不同表達法的練習量。",
        "Va": "在小眾語言翻譯中，沒了反向翻譯，資料太少會讓模型死記硬背，泛化效果極差。",
        "Dif": "A 會讓過擬合更嚴重；C 僅是參數壓縮；D 會限制模型適應新語言的能力。"
    },
    {
        "id": "136301_20",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "在使用生成對抗網路(GAN)進行人臉影像生成時，若出現「模式崩潰」(Mode Collapse)現象，下列哪一種方法最常被用來有效解決此問題？",
        "A": "在鑑別器中加入梯度懲罰(Gradient Penalty)以穩定訓練過程",
        "B": "採用 Wasserstein 距離(WGAN 損失)替代原始的 GAN 損失函數",
        "C": "對生成器輸入的潛在向量加入隨機擾動",
        "D": "使用多尺度鑑別器架構以提高對多樣性的判別能力",
        "Ans": "B",
        "has_img": false,
        "Exp": "WGAN 使用 Wasserstein 距離改善梯度消失，提供更平滑的引導，避免生成器只學會單一圖像。",
        "Ex": "像在迷宮中把斷崖換成斜坡，讓機器人不會一直摔進同一個死胡同，能探索更多出口。",
        "Va": "用於高品質、多樣化的影像生成；若無此技術，GAN 常會重複產生一模一樣的臉孔。",
        "Dif": "A為WGAN-GP的改良手段；C無法解決損失函數本質問題；D是針對解析度與複雜度，非崩潰問題。"
    },
    {
        "id": "136301_21",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "在多模態 AI 模型訓練或推論過程中，遇到某一模態資料缺失(例如僅有影像資料但缺少文本說明)，下列哪一種策略最有效維持模型效能？",
        "A": "以零向量或固定向量填充缺失模態輸入",
        "B": "訓練具備模態缺失感知能力的模型，使其適應缺失狀況",
        "C": "利用生成模型(如 GAN 或自迴歸模型)預測並補全缺失模態資料",
        "D": "直接捨棄缺少模態的樣本，避免干擾訓練或推論",
        "Ans": "B",
        "has_img": false,
        "Exp": "透過訓練讓模型學習處理部分資訊缺失的狀況，確保在資訊不完整時仍能做出正確判斷。",
        "Ex": "像訓練特種兵即使在黑夜看不見，也能靠聽覺作戰，而不是因為沒視覺就完全無法行動。",
        "Va": "應用於自駕車感測器故障或醫療病歷不全；沒了它，系統只要一個感測器失效就會徹底罷工。",
        "Dif": "A會引入無意義噪音；C運算成本極高且預測可能錯誤；D會導致大量珍貴樣本被浪費。"
    },
    {
        "id": "136301_22",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某電商平台開發的顧客流失預測模型在上線數月後，預測準確率明顯下降。\n專案團隊懷疑顧客行為模式改變，導致模型輸入特徵的分佈與原始訓練資料不同，出現典型的資料漂移(Data Drift)問題。\n為了偵測並確認資料分佈是否發生變化，下列哪一種作法最合適？",
        "A": "定期重新訓練模型以應對外部變化",
        "B": "提升模型複雜度以捕捉更多資料變異性",
        "C": "增加測試資料量以提高評估準確度",
        "D": "計算輸入特徵分佈間的 KL 散度(KL Divergence)",
        "Ans": "D",
        "has_img": false,
        "Exp": "KL 散度是衡量兩個機率分佈差異的量化工具，能精確偵測新舊資料分佈是否「走鐘」。",
        "Ex": "就像拿現在顧客的口味清單跟半年前比，計算兩份清單的重疊度，看客人的喜好是否大搬風。",
        "Va": "模型監控預警；沒了它，模型會持續用過時的經驗做錯誤預測，導致企業決策失誤。",
        "Dif": "A是解決方案而非偵測手段；B會導致過擬合；C無法解釋分佈為何發生偏差。"
    },
    {
        "id": "136301_23",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L213_AI技術應用與系統部署",
        "tags": [],
        "Q": "某大型醫院即將部署一套輔助診斷的 AI 系統，為降低對臨床流程的衝擊，同時確保風險可控與回饋可收斂，應採取何種『漸進式部署』 (Phased Rollout)策略最為合適？",
        "A": "從單一專科(如放射科)或特定病房開始啟用，逐步擴展至全院",
        "B": "先部署於病例量較高的急診單位，加速收集高頻使用回饋",
        "C": "僅在夜班或離峰時段啟用，避免影響主要臨床工作負載",
        "D": "在使用者界面啟用提示模式，讓全院同步體驗但不影響診斷流程",
        "Ans": "A",
        "has_img": false,
        "Exp": "先在小範圍受控環境實施，能集中資源排除問題，待系統穩定後再大規模推廣。",
        "Ex": "新口味飲料試賣時，先在一家超商上架測試，確定沒問題後再鋪貨到全台灣連鎖店。",
        "Va": "高風險系統（如金融、醫療）部署；沒了它，系統一旦有 Bug 會造成全院性的嚴重癱瘓。",
        "Dif": "B急診風險最高最混亂；C夜班人力少難排除突發狀況；D範圍太大，風險難以控制。"
    },
    {
        "id": "136301_24",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某金融機構的 AI 風控系統遭受對抗性攻擊，駭客透過對輸入特徵進行微小但惡意的擾動，成功欺騙了模型。為了從根本上解決模型自身對這類攻擊的脆弱性，下列何者並非針對此種攻擊型態的技術手段？",
        "A": "強化資料前處理，用以過濾掉格式不符或數值極端異常的輸入",
        "B": "在模型訓練階段導入對抗樣本訓練，以提升模型對惡意特徵擾動的辨識與防禦能力",
        "C": "於推論後階段使用規則引擎，以確保模型的預測結果不違反既有的業務硬性規定",
        "D": "在模型部署環境中強化網路防火牆，以阻擋來自未授權來源的網路連線",
        "Ans": "D",
        "has_img": false,
        "Exp": "防火牆阻擋「非法進入」，但對抗性攻擊通常是偽裝成「合法請求」的惡意內容，防火牆攔不住。",
        "Ex": "對抗攻擊像是客人穿西裝進門卻在菜裡下毒，防火牆只是門口守衛，防不了已經進門的毒藥。",
        "Va": "模型安全性加固；必須靠 A、B、C 強化「免疫力」，否則模型極易被精心設計的輸入欺騙。",
        "Dif": "A、B、C 皆針對「資料內容」或「模型邏輯」防禦，D 屬於傳統網路層安全，非針對模型漏洞。"
    },
    {
        "id": "136301_25",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某企業部署生成式 AI 系統協助行銷與內容產出，但近期遭質疑部分生成內容可能涉及著作權侵權。為降低企業在法律層面的潛在責任與風險，下列哪一項策略最能有效預防侵權問題產生？",
        "A": "對生成內容進行語意相似度比對，自動標註可能涉及既有著作的輸出結果，以降低侵權風險",
        "B": "建立訓練資料篩選與授權驗證機制，排除未授權或高風險資料來源",
        "C": "在訓練與微調過程中採用差分隱私技術，避免模型記憶特定受著作權保護的樣本",
        "D": "在模型輸出端嵌入浮水印(Watermarking)或數位指紋(Digital Fingerprint)技術，以確保生成內容可追溯",
        "Ans": "B",
        "has_img": false,
        "Exp": "從源頭管理訓練資料最能防止侵權，只要模型沒看過沒授權的內容，就不會產出侵權物。",
        "Ex": "像大廚煮飯前先檢查食材都有收據且合法，就不怕被控告使用了偷來的秘方材料。",
        "Va": "企業合規與智財保護；沒了它，企業可能面臨天價賠償及商譽受損。",
        "Dif": "A是事後檢查；C是保護個資隱私而非版權；D僅能追蹤來源，無法阻止侵權內容產出。"
    },
    {
        "id": "136301_26",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L233_機器學習建模與參數調校",
        "tags": [],
        "Q": "在房價預測任務中，若發現特徵如「房間數」與「坪數」存在高度多重共線性(Multicollinearity)，為降低共線性對模型參數估計的負面影響，應優先選擇下列哪種模型？",
        "A": "不受多重共線性影響的決策樹模型",
        "B": "傳統線性迴歸模型，不含正則化項",
        "C": "支持向量機搭配線性核函數",
        "D": "含 L1 正則化的 LASSO 迴歸模型",
        "Ans": "D",
        "has_img": false,
        "Exp": "LASSO 透過 L1 正則化能將重複、無用特徵的係數壓縮至零，自動進行特徵選擇。",
        "Ex": "就像隊伍裡有兩個功能重疊的隊員，LASSO 會強迫其中一個休息，讓另一個專心發揮。",
        "Va": "用於高維度資料分析；沒了它，模型的預測結果會變得極不穩定，且無法正確判斷特徵重要性。",
        "Dif": "A雖不受影響但題意是要求「參數估計」；B會導致係數爆炸；C對共線性敏感度依然存在。"
    },
    {
        "id": "136301_27",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L222_大數據處理技術",
        "tags": [],
        "Q": "某企業需分析半結構化的系統日誌(JSON 格式)，以提取關鍵的時序特徵供故障預測模型使用。考量日誌結構複雜且包含巢狀欄位(Nested Fields)，下列哪一種策略最有效且實務可行？",
        "A": "先將 JSON 資料扁平化轉成 CSV，再對欄位計算統計量(如均值、次數)作為特徵",
        "B": "使用遞歸神經網路(RNN)直接輸入原始 JSON 字串進行時序特徵抽取",
        "C": "設計遞迴函式展開巢狀欄位，並基於時間窗口(Time Window)進行聚合與特徵萃取",
        "D": "只保留時間戳記欄位，忽略其他巢狀內容以簡化特徵工程",
        "Ans": "C",
        "has_img": false,
        "Exp": "遞迴展開能完整保留資料結構，搭配時間窗口聚合能有效捕捉行為隨時間變化的特徵。",
        "Ex": "像拆開層層套疊的俄羅斯娃娃，並把每分鐘拆出來的零件分類統計，找出故障規律。",
        "Va": "伺服器監控與資安偵測；沒了它，模型讀不懂複雜日誌，會漏掉關鍵的故障預警。",
        "Dif": "A會遺失階層資訊；B直接讀字串效果極差；D捨棄太多重要資訊。"
    },
    {
        "id": "136301_28",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "在一個同時包含連續型特徵與類別型特徵的資料集中，若希望透過適當的特徵工程流程來提升模型整體表現，下列哪一種作法最為合適？",
        "A": "將類別型特徵使用標籤編碼(Label Encoding)轉換後，與連續特徵直接合併進行模型訓練",
        "B": "將連續特徵進行離散化(Discretization)或分桶(Binning)轉為類別型特徵，統一以類別方式處理",
        "C": "對連續特徵做標準化(Standardization)，類別特徵採用目標編碼(Target Encoding)，並生成交互特徵提升模型表現",
        "D": "只保留連續特徵，忽略類別型變量以簡化模型",
        "Ans": "C",
        "has_img": false,
        "Exp": "標準化消除單位差異，目標編碼處理類別更有效，交互特徵則能捕捉變數間的隱藏關聯。",
        "Ex": "像把球員身高標準化、國籍轉成勝率指標，再把「身高x體重」結合看爆發力，數據最準。",
        "Va": "數據建模標配流程；沒了它，模型會因特徵尺度不一或類別處理不當而導致訓練困難。",
        "Dif": "A標籤編碼會有虛假順序大小；B會損失數值精確度；D損失大量分類資訊。"
    },
    {
        "id": "136301_29",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L213_AI技術應用與系統部署",
        "tags": [],
        "Q": "某 AI 開發團隊為提升模型開發效率及品質控制，計畫實施持續整合(Continuous Integration, CI)流程。下列哪一項做法最符合 CI的核心實踐，且能有效減少整合風險？",
        "A": "在主分支(Main Branch)每日固定時間手動合併並執行完整測試流程",
        "B": "每次程式碼提交(Commit)後自動觸發建置、單元測試及靜態程式碼分析",
        "C": "於模型訓練完成後，定期安排開發團隊回顧並合併程式碼",
        "D": "透過自動化部署腳本，將模型在特定時間點批次釋出到測試環境",
        "Ans": "B",
        "has_img": false,
        "Exp": "CI 核心在於自動化與高頻率，只要有變動就立即檢查，確保程式碼隨時處於健康狀態。",
        "Ex": "像廚房每切好一道菜就立刻檢查新鮮度，而不是等到整桌菜煮完才發現第一道菜早就壞了。",
        "Va": "軟體與 AI 自動化開發；沒了它，團隊開發會因程式碼衝突和隱藏 Bug 導致進度嚴重延遲。",
        "Dif": "A不夠即時且依賴手動；C是代碼審核而非CI；D屬於 CD（持續部署/釋出）範疇。"
    },
    {
        "id": "136301_30",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L213_AI技術應用與系統部署",
        "tags": [],
        "Q": "某銀行計劃將 AI 詐欺偵測模組整合至核心交易系統，主管機關要求全流程必須符合金融監管對「不可否認性(Non-repudiation)」的資訊安全規範，以確保日後能進行法務追蹤與稽核。\n下列哪一項措施最能確保此要求的落實？",
        "A": "為每筆 AI 模型推論記錄其輸入與輸出結果的加密雜湊值(Hash)，並簽署數位簽章以確保不可竄改性",
        "B": "優化模型效能以降低平均推論延遲至 100ms 以下，提升使用者體驗",
        "C": "增加主機備援數量，以確保系統在故障時持續可用",
        "D": "將模型推論請求導入負載平衡器，避免單點壅塞導致服務延遲",
        "Ans": "A",
        "has_img": false,
        "Exp": "透過數位簽章與哈希值，能證明資料在特定時間由誰產出且未被修改，事後無法賴帳。",
        "Ex": "就像在合約上蓋上無法偽造的鋼印並標註時間，之後誰都不能說這份合約是假的或改過的。",
        "Va": "金融法規合規與法律證據；沒了它，交易爭議時無法證明是誰發起或系統如何判定。",
        "Dif": "B與速度有關；C與可用性有關；D與效能分配有關，皆與不可否認性無關。"
    },
    {
        "id": "136301_31",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L213_AI技術應用與系統部署",
        "tags": [],
        "Q": "某 AI 服務系統每次推論請求需約 1 秒完成，且必須支撐高達 10,000次請求每秒(RPS)的流量。為確保系統具備高可用性且能穩定應付流量峰值，下列哪一種架構方案最為合適？",
        "A": "依賴單台超高效能伺服器進行垂直擴展，提升硬體規格",
        "B": "採用容器化部署並水平擴展服務實例，結合自動彈性伸縮機制(Auto Scaling)",
        "C": "限制最大併發連線數，以避免系統過載",
        "D": "增加批次處理大小，一次同時處理上千筆請求",
        "Ans": "B",
        "has_img": false,
        "Exp": "水平擴展可透過增加機器分攤壓力，Auto Scaling 能隨流量自動增減，確保穩定。",
        "Ex": "餐廳客滿時，不是買更大的烤箱，而是多開幾家分店來接客，客少時再關店節省成本。",
        "Va": "大型網路服務（如雙11購物）；沒了它，流量高峰時伺服器會崩潰導致服務中斷。",
        "Dif": "A有硬體上限且單點失效風險高；C會拒絕合法客戶；D會大幅增加單次請求延遲。"
    },
    {
        "id": "136301_32",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某企業已將 AI 模型部署於生產環境，為確保系統持續穩定運作，並能提前偵測模型效能可能衰退，技術團隊希望透過監控指標進行預警。下列哪一項監控指標最具預測效力，能提早發現模型效能下滑風險？",
        "A": "系統 CPU 與記憶體使用率波動幅度",
        "B": "模型推論結果的置信度(Confidence)分佈變化趨勢",
        "C": "API 平均回應時間與延遲百分位數變化",
        "D": "輸入特徵與訓練資料分布差異的 PSI(Population Stability Index)指數",
        "Ans": "D",
        "has_img": false,
        "Exp": "PSI 指數能量化「當前資料」與「訓練資料」的差異，分佈一變通常預示效能即將下滑。",
        "Ex": "就像氣壓計能預測暴雨；當顧客進店的樣貌開始變得很奇怪，業績遲早會掉。",
        "Va": "模型維運（MLOps）監控；沒了它，模型變差時你得等虧損發生了（延後指標）才會知道。",
        "Dif": "A、C是硬體指標；B雖相關但不如 PSI 直接反映資料根源的變化。"
    },
    {
        "id": "136301_33",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "企業團隊在使用 Word2Vec 模型訓練客服文本語料時，若訓練資料量龐大且希望模型能更有效捕捉罕見詞的語意關聯，下列哪一種訓練策略最為適合？",
        "A": "採用 Skip-gram 模型，但以隨機初始化權重加快高頻詞的訓練收斂",
        "B": "採用 CBOW 模型(Continuous Bag of Words Model)並結合 TFIDF 權重以強化低頻詞表示",
        "C": "採用 Skip-gram 模型，利用中心詞預測周圍詞語，能更有效學習低頻詞關係",
        "D": "採用 CBOW 模型(Continuous Bag of Words Model)，利用周圍詞預測中心詞，能提升罕見詞的語意穩定度",
        "Ans": "C",
        "has_img": false,
        "Exp": "Skip-gram 讓每個詞都作為中心詞預測周邊，增加罕見詞的訓練次數，對低頻詞效果好。",
        "Ex": "像派對上讓每個人都上台講話（中心詞），而不是只聽一群人的大聲總結（CBOW）。",
        "Va": "專業領域 NLP 建模；沒了它，模型對於專業術語或冷門字詞的理解會非常粗淺。",
        "Dif": "CBOW 是用環境猜中間，會平滑掉罕見詞特徵，較適合高頻詞與大語料快速訓練。"
    },
    {
        "id": "136301_34",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "在自駕車影像辨識系統中，開發團隊希望模型能同時辨識每個像素所屬的物件類別(例如道路、建築、行人)，又能區分出同類物件的不同個體(例如多位行人)。此時最適合採用下列哪一項電腦視覺技術？",
        "A": "語義分割(Semantic Segmentation)",
        "B": "物件偵測(Object Detection)",
        "C": "實例分割(Instance Segmentation)",
        "D": "全景分割(Panoptic Segmentation)",
        "Ans": "D",
        "has_img": false,
        "Exp": "全景分割整合了語義分割（分種類）與實例分割（分個體），是像素級的最全面解析。",
        "Ex": "不僅要把照片中的「人」跟「路」塗不同色，還要幫每個「人」標上 1, 2, 3 號。",
        "Va": "自駕車環景辨識；沒了它，車子可能知道前面有一群人，卻分不清是幾個、誰在動。",
        "Dif": "A不分個體；B只給框不給精確邊緣；C通常不處理背景類（如天空、草地）。"
    },
    {
        "id": "136301_35",
        "sub": "AI應用規劃師",
        "level": "中級",
        "year": "114",
        "type": "選擇",
        "status": "published",
        "src": "114年IPAS AI_中級_科目1_人工智慧技術應用與規劃_136301",
        "L1": "L21_人工智慧技術應用與規劃",
        "L2": "L211_AI相關技術應用",
        "tags": [],
        "Q": "某媒體公司計畫導入 CLIP(Contrastive Language–Image Pretraining)模型，以協助大量影像自動標註與搜尋，並希望在無需新增標訓資料的情況下，僅透過文字提示(Text Prompt)即可識別影像內容。\n請問此應用情境中，CLIP 能夠達成的關鍵技術特性為何？",
        "A": "透過圖文對比式學習(Contrastive Learning)將影像與文字映射至共同嵌入空間(Shared Embedding Space)，可直接以語意相似度進行零樣本分類",
        "B": "透過影像增強與特徵擴散降低標訓資料需求",
        "C": "以監督式學習結合多層感知器(Multilayer Perceptron, MLP)進行影像特徵分類",
        "D": "以自迴歸生成模型(Autoregressive Model)逐步生成文字標籤描述影像內容",
        "Ans": "A",
        "has_img": false,
        "Exp": "CLIP 把圖、文拉到同一維度比較，模型靠文字語意就能辨識從未見過的特定標籤圖片。",
        "Ex": "像翻譯官把照片和德文都翻成中文，即使沒見過那張圖，只要標題對得上他就能找出來。",
        "Va": "圖庫搜尋與自動標註；沒了它，要辨識新物品就得重新標記數萬張圖並重新訓練。",
        "Dif": "B、C 是傳統做法；D 是影像描述生成，與「識別影像內容」的分類比對原理不同。"
    }
]